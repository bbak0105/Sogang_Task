# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VbscLOFPe67ZWZGCb9Nc6hEfOSIUFrfs
"""

############# 1번 전처리 과정 #############
!pip install requests
import requests
from bs4 import BeautifulSoup
import re
# 영화 제목(title)과 url 추출
url1 = 'https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&ref_=adv_prv'
url2 = 'https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start=51&ref_=adv_nxt'
url3 = 'https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start=101&ref_=adv_nxt'
url4 = 'https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start=151&ref_=adv_nxt'
url5 = 'https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start=201&ref_=adv_nxt'
url_list = [url1, url2, url3, url4, url5]

rank_list = []
title_list = []
year_list = []
runtime_list = []
genre_list = []
director_list = []
rating_list = []

for url_i in url_list:
  url = url_i 
  req = requests.get(url)
  html = req.text
  soup = BeautifulSoup(html, "html.parser")

  for i in range(0,50):
    rank = re.sub('\.', '', soup.select(".lister-item-index")[i].text)
    title = soup.select(".lister-item-header > a")[i].text
    year = re.sub('\(|\)', '', soup.select(".lister-item-year")[i].text)
    runtime = float(re.sub('min', ' ', soup.select(".runtime")[i].text))
    genre = re.sub('\\n', '', soup.select(".genre")[i].text)
    director = soup.select("p > a:nth-of-type(1)")[i].text
    rating = float(soup.select(".inline-block > strong")[i].text)
    rank_list.append(rank)
    title_list.append(title)
    year_list.append(year)
    runtime_list.append(runtime)
    genre_list.append(genre)
    director_list.append(director)
    rating_list.append(rating)
    # print(i)

movie_list = zip(rank_list, title_list, year_list, runtime_list, genre_list, director_list, rating_list)
movie_info_list = []
for movie in movie_list:
    movie_dict = {
        "rank": movie[0],
        "title": movie[1],
        "year": movie[2],
        "runtime": movie[3],
        "genre": movie[4],
        "director": movie[5],
        "rating": movie[6]
    }

    movie_info_list.append(movie_dict)

# movie_info_list

# 1) 가장 빈도가 높은 상위 3개 연도(year)는 언제인가?
import pandas as pd

len(movie_info_list)
movie_data = pd.DataFrame(movie_info_list)
movie_data
movie_data.groupby(["year"]).count()
print(movie_data["year"].value_counts()[:3])
### 1) 답: 1995, 2004, 2009

# 2) 연도별 rating의 평균을 이용해서 평균치가 가장 높은 연도와 평균치를 구하시오. 
newdata = movie_data[['year','rating']]
new2 = newdata.groupby(['year']).mean()
# type(new2) => dataFrame
new2.sort_values('rating', ascending=False)[:1] #rating 순으로, descending(내림차순 정렬)
print(new2.sort_values('rating', ascending=False)[:1])
### 2) 답: 1972, 9.2

# 3) 가장 빈도가 높은 쟝르(genre)는 무엇이며 몇 편인가?
# (단, 여러 쟝르 조합은 하나의 별도의 쟝르로 구분한다)
movie_data.groupby(["genre"]).count()
print(movie_data["genre"].value_counts()[:1])
### 3) 답: Drama, 20편

# 4) 6편 이상을 제작한 감독(director)는 누구인가?
print(movie_data["director"].value_counts() >= 6)
### 4) 답: Christopher Nolan, Akira Kurosawa, Stanley Kubrick, Martin Scorsese, Steven Spielberg

# 5) 상영시간(runtime)이 70분 미만인 작품은 총 몇 편인가?
print(len(movie_data[movie_data['runtime']<70]))

############# 2번 전처리 과정 #############
!pip install requests
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
url = "https://movie.naver.com/movie/sdb/rank/rmovie.nhn?sel=pnt&date=20201108"
req = requests.get(url)
html = req.text
soup = BeautifulSoup(html, "html.parser")

# 1) 2개의 변수(영화명, 평점, 상세url)를 포함하는 data frame을 만드는 코드를 아래 명령문을 이용하여 작성하시오.
# for (a,b) in zip(A, B)
titles = soup.select(".tit5 a")
ratings = soup.select(".point")
title_list = []
url_list = []
rating_list = []
for (title, rate) in zip(titles, ratings):
    title_list.append(title.text)
    url_list.append(title["href"])
    rating_list.append(rate.text)

movie_list1 = zip(title_list, url_list, rating_list)
movie_data = pd.DataFrame(movie_list1)
print(movie_data)

############# 2-2번 전처리 과정 #############
movie_site = "https://movie.naver.com"
score_list = []
type_list = []
country_list = []
run_time_list = []
open_time_list = []
###############################################################
for url_i in url_list:    
    html_new = requests.get(movie_site + url_i).text
    soup_new = BeautifulSoup(html_new, "html.parser")
    try:
      score = float(re.sub(r'[^0-9]', '', soup_new.select(".star_score > span > span")[0].text))
    except:
      score = None
    type1 = soup_new.select(".info_spec dd > p > span")[0].text
    type1 = re.sub('\t|\r|\n', '', type1)
    country = soup_new.select(".info_spec dd > p > span")[1].text
    country = re.sub('\t|\r|\n', '', country)
    try:
      run_time = soup_new.select(".info_spec dd > p > span")[2].text
      run_time = re.sub('\t|\r|\n', '', run_time)
      run_time = float(re.sub(r'[^0-9]', '', run_time))
    except:
      run_time = None
    try:
      open_time = soup_new.select(".info_spec dd > p > span")[3].text
      open_time = re.sub('\t|\r|\n|\s', '', open_time)[0:4]
    except:
      open_time = None
    score_list.append(score)
    type_list.append(type1)
    country_list.append(country)
    run_time_list.append(run_time)
    open_time_list.append(open_time)
    # print(len(score_list))
############## 영화 정보 작성 (title, score, type, country, run_time, open_time 묶음)
movie_list = zip(title_list, score_list, type_list, country_list, run_time_list, open_time_list)
movie_info_list = []

for movie in movie_list:
    movie_dict = {
        "title": movie[0],
        "score": movie[1],
        "type": movie[2],
        "country": movie[3],
        "run_time": movie[4],
        "open_time": movie[5]
    }
    movie_info_list.append(movie_dict)
movie_info_list


import pandas as pd
movie_data2 = pd.DataFrame(movie_info_list)

# 2) 쟝르가 [다큐멘터리]인 영화의 제목은 무엇인가?
newData5 = movie_data[['title','type']]
newData5[newData5['type'] == '다큐멘터리']
### 2) 답: 부활:그증거, 주전장, 브레이크 더 사일런스:더무비

# 3) 영화국적의 빈도가 가장 높은 나라는?
movie_data2["country"].value_counts()[:1]
### 3) 답: 미국

# 4) 개봉연도 기준으로 관람객평점의 평균이 가장 높은 [1] 개봉연도와 [2] 평균평점를 구하시오.
# 여기서, 관람객평점 결측치가 있는 연도는 데이터에서 제외시킨 뒤 계산 하시오.
# (힌트: data.dropna(axis=0) 이용)
newData3 = movie_data2[['open_time','score']]
new3 = newData3.groupby(['open_time']).mean()
new3.sort_values('score',ascending=False).dropna(axis=0)
### 4) 답: 2003, 972

# 5) 쟝르 기준으로 상영시간의 평균이 가장 긴 쟝르를 구하시오.
newData4 = movie_data2[['type','run_time']]
new4 = newData4.groupby(['type']).mean()
new4.sort_values('run_time',ascending=False)
### 5) 답: 판타지, 모험, 액션, 전쟁